{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¦ Fraud Detection using Machine Learning\n",
    "\n",
    "## Files Description  \n",
    "notebooks/fraud_detection.ipynb\tMain Jupyter Notebook with fraud detection model implementation.  \n",
    "\n",
    "data/creditcard.csv\tDataset containing credit card transactions.  \n",
    "\n",
    "requirements.txt\tList of required Python libraries.  \n",
    "\n",
    "results/\tExported PDF and HTML versions of the Jupyter Notebook.\n",
    "\n",
    "## ğŸ“Œ Project Overview\n",
    "This project aims to detect fraudulent transactions using machine learning models, particularly **LightGBM and XGBoost**, enhanced with **anomaly detection** techniques. The final model helps identify fraudulent transactions while minimizing false positives and false negatives.\n",
    "\n",
    "## ğŸ“‚ Dataset\n",
    "- **Source**: Credit card transactions dataset\n",
    "- **Features**:\n",
    "  - `Time`: Timestamp of the transaction\n",
    "  - `V1-V28`: PCA-transformed features to anonymize sensitive data\n",
    "  - `Amount`: Transaction amount\n",
    "  - `Class`: Target variable (0 = Normal Transaction, 1 = Fraudulent Transaction)\n",
    "- **Size**: ~285,000 transactions\n",
    "\n",
    "## ğŸ” Exploratory Data Analysis (EDA)\n",
    "Key observations:\n",
    "- Fraudulent transactions account for only **0.17%** of the dataset (highly imbalanced data).\n",
    "- Distribution analysis shows that **fraudulent transactions are lower in value** compared to normal ones.\n",
    "- Feature correlation indicates that some PCA-transformed features (`V4`, `V11`, `V17`, etc.) are highly correlated with fraud.\n",
    "\n",
    "## ğŸ› ï¸ Data Preprocessing\n",
    "1. **Handling Imbalance**: Applied **SMOTE (Synthetic Minority Over-sampling Technique)** to balance fraud cases.\n",
    "2. **Feature Scaling**: Standardized `Amount` feature to match the PCA-scaled features.\n",
    "3. **Anomaly Detection**: Used **Isolation Forest** to generate an `anomaly_score` as a new feature.\n",
    "4. **Train-Test Split**: Data was split into **80% training / 20% testing**.\n",
    "\n",
    "## ğŸ“Š Model Selection & Evaluation\n",
    "### **1ï¸âƒ£ XGBoost Model**\n",
    "| Metric      | Score  |\n",
    "|------------|--------|\n",
    "| Precision  | 0.79   |\n",
    "| Recall     | 0.86   |\n",
    "| F1-score   | 0.82   |\n",
    "| AUC-ROC    | 0.9868 |\n",
    "\n",
    "### **2ï¸âƒ£ LightGBM Model** (Final Model)\n",
    "| Metric      | Score  |\n",
    "|------------|--------|\n",
    "| Precision  | 0.62   |\n",
    "| Recall     | 0.87   |\n",
    "| F1-score   | 0.72   |\n",
    "| AUC-ROC    | 0.9717 |\n",
    "\n",
    "### **ğŸ“ˆ Business Implications**\n",
    "\n",
    "ğŸ”¹ Reducing False Positives: Helps prevent unnecessary transaction declines for legitimate users.\n",
    "ğŸ”¹ Reducing False Negatives: Ensures that fraudulent activities are detected before financial losses occur.\n",
    "ğŸ”¹ Scalability: The model can be deployed in real-time fraud detection systems used by financial institutions.\n",
    "\n",
    "### ğŸ› ï¸ Technologies Used\n",
    "\n",
    "Python (Pandas, NumPy, Matplotlib, Seaborn)\n",
    "\n",
    "Machine Learning (Scikit-learn, XGBoost, LightGBM, Imbalanced-learn)\n",
    "\n",
    "Data Processing (SMOTE, Isolation Forest, PCA, StandardScaler)\n",
    "\n",
    "Visualization (Matplotlib, Seaborn, Plotly)\n",
    "\n",
    "Jupyter Notebook for interactive analysis\n",
    "\n",
    "ğŸ† **XGBoost was chosen as the final model due to its superior recall and AUC-ROC scores.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
